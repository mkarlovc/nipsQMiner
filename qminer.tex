\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}



\usepackage{listings}
\usepackage{color}

\definecolor{lightgray}{rgb}{1,1,1}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{redstrings}{rgb}{0.64,0.08,0.08}
\definecolor{blue}{rgb}{0,0,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\renewcommand{\lstlistingname}{Code fragment}


\lstdefinelanguage{JavaScript}{
  keywords={break, case, catch, continue, debugger, default, delete, do, else, finally, for, function, if, in, instanceof, new, return, switch, this, throw, try, typeof, var, void, while, with, null},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{blue}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{greencomments}\ttfamily,
  stringstyle=\color{redstrings}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   backgroundcolor=\color{lightgray},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}


%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{QMiner – Data Analytics Platform for Processing Streams of Structured and Unstructured Data}


\author{
Blaz Fortuna, Jan Rupnik, Carolina Fortuna, Marko Grobelnik, \\
Viktor Jovanoski, Mario Karlovcec, Blaz Kazic, Klemen Kenda, \\
Gregor Leban, Jost Novljan, Miha Papler, Luis Rei, Blaz Sovdat, \\
Luka Stopar, Andrej Muhic \\
Department of Computer Science\\
Jožef Stefan Institute\\
Jamova cesta 39, Ljubljana, Slovenia \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% \nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
QMiner is an open source analytics platform for performing large scale data analysis.
The paper presents the main features, capabilities and design choices of the library, which
is followed by examples.
\end{abstract}

\section{Introduction}
QMiner grew from several EU Framework Programme projects in the areas of text, web, and stream mining over the last couple of years. The developed solutions focus on interactivity and operate in real-time on data sets of 100s of GBs on high-end commodity hardware. These goals and constraints resulted in a unique set of features that we implemented in QMiner.
QMiner applications are implemented in JavaScript, making it easy for novice users to get started. Using the JavaScript API it is easy to compose complete data processing pipelines and integrate with other systems via RESTful web services. The backend is implemented in C++ and can be included as a library into custom C++ projects, thus providing them with stream processing and data analytics capabilities.
QMiner is available as open source project in GitHub under AGPL licence. The repository contains source code, introduction guide and complete documentations of QMiner JavaScript APIs.
We will first present the core components of the library and then present some examples using the javascript API.

\section{Building blocks}
The core blocks of the library are as follows.

\textbf{Storage and index layer:}

\textbf{stream aggregates:}

\textbf{feature extractors:} A feature extractor enables mapping records to linear algebra vectors (supports dense and sparse vectors). 
The core framework for feature extractors enables constructing and gluing several types of feature extractors and automatically performs all the necessary bookkeeping. 
Feature extractors include: numeric feature extractors, text feature extractors (bag of words), element indicator vectors and set indicator vectors (multi-label). In addition, when working with the javascript API, feature extractors implemented as javascript functions are supported.

\textbf{analytics:} The analytics components include several popular machine learning algorithms for clustering, dimensionality reduction, classification, regression and
 active-learning.

\textbf{linear algebra:} The library includes manipulation of several implementations of vectors and matrices. Algorithms enable solving linear systems and computing several
matrix decompositions. Randomization based algorithms enable solving large scale problems, such as SVDs on large structured or sparse matrices. The QMiner library can optionally be compiled with Intel MKL library which is highly optimized.




\section{Features}
We now list some of the notable features of QMiner.

\textbf{Connecting storage, indexing and analytics:} QMiner stores and indexes the data in a way that makes the implemented machine learning methods more scalable. Computing feature vectors from stored records aims at reducing duplication of data in the process and relies heavily on the integrated indexing and its features (e.g. probabilistic joins) to make the transformations faster. Data schemas provide types for directly storing vectors and sparse vectors as part of records.

\textbf{Multimodal data support:} QMiner provides native support for handling and learning from unstructured data such as text or graphs. For example, full text search, aggregation over text fields, creating and storing bag-of-words vectors directly in the data stores, and full integration of Stanford graph analysis library SNAP in the C++ and JavaScript APIs

\textbf{Processing streaming data:} QMiner provides building blocks for processing and learning from streams of text documents, website logs or numeric streams. For example, pipeline-able stream aggregates for maintaining aggregate statistics over the stream, and machine learning algorithms for learning from stream.

\textbf{Probabilistic joins between tables:} For some operations computing a complete join between tables is not necessary. For example, to compute the gender distribution of visitors of a particular web page, we do not really need a complete list of visitors for that particular web page. What suffices is a statistically representative sample. QMiner supports several sampling techniques for achieving this, and integrates the support for probabilistic joins in query language and feature extractors.

\textbf{Efficiency and fast prototyping:} All main components of the library are implemented in C++ and are optimized for memory usage and computational speed. This involves
the data store, indexing, feature extractors, linear algebra, stream processing components, several machine learning and graph mining algorithms (based on SNAP library). Most of the
core functionality is exposed in the javascript API which enables fast prototyping and deploying as RESTful services.


\section{Examples}
QMiner lets you get from data to working models exposed through web service API in less then an hour. Most applications can be scripted fully in the JavaScript layer, taking advantage of components implemented in C++ and libraries such as Intel MKL.


\subsection{Text processing, classification and regression}

This example shows how to extract features from the movie dataset and use them to build classification and regression models to predict movie genre and rating.

\begin{lstlisting}[caption={Text mining: storage, feature extraction, classification and regression}] 	
// Import analytics module
var analytics = require("analytics.js");
// Loading in the dataset.
qm.load.jsonFile(Movies, "./sandbox/movies/movies.json");
 	
// Declare the features we will use to build genre classification models
var genreFeatures = [
    { type: "text", source: "Movies", field: "Title" },
    { type: "text", source: "Movies", field: "Plot" },
    { type: "join", source: { store: "Movies", join: "Actor" } },
    { type: "join", source: { store: "Movies", join: "Director"} }
];
// Create a model for the Genres field, using all the movies as training set.
var genreModel = analytics.newBatchModel(Movies.recs,
                    genreFeatures, Movies.field("Genres"));
// Predict genres of a new movie
var newMovie = qm.store("Movies").newRec(/*{...}*/);
var result = genreModel.predict(newMovie);
\end{lstlisting}



\subsection{Time series processing}
The following example demonstrates how to perform time series resampling, feature vector computation and prediction.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.5\textwidth]{timeSeries.png}
\end{center}
\caption{Time series processing architecture}
\end{figure}

\begin{lstlisting}[caption=Time series processing] 	
// Initialize resamper from Raw to Resampled store. This results in
// in an equaly spaced time series with 10 second interval.
Raw.addStreamAggr({
    name: "Resample10second", type: "resampler",
    outStore: "Resampled", timestamp: "Time",
    fields: [{ name: "Value", interpolator: "previous" }],
    createStore: false, interval: 10 * 1000
});
// Initialize stream aggregates on Resampled store for computing
// 1 minute and 10 minute exponential moving averages.
Resampled.addStreamAggr({
    name: "tick", type: "timeSeriesTick",
    timestamp: "Time", value: "Value"
});
Resampled.addStreamAggr({
    name: "ema1m", type: "ema",
    inAggr: "tick", emaType: "previous", interval: 60000
});
Resampled.addStreamAggr({
    name: "ema10m", type: "ema",
    inAggr: "tick", emaType: "previous", interval: 600000
});
// Buffer for keeping track of the record from 1 minute ago
Resampled.addStreamAggr({ name: "delay", type: "recordBuffer", size: 6 });

// Declare features from the resampled timeseries
var ftrSpace = analytics.newFeatureSpace([
    { type: "numeric", source: "Resampled", field: "Value" },
    { type: "numeric", source: "Resampled", field: "Ema1" },
    { type: "numeric", source: "Resampled", field: "Ema2" },
    { type: "multinomial", source: "Resampled", field: "Time", datetime: true }
]);
// Initialize linear regression model.
var linreg = analytics.newRecLinReg({ dim: ftrSpace.dim, forgetFact: 1.0 });
// We register a trigger to Resampled store
Resampled.addTrigger({
    onAdd: function (val) {
        // Get the latest value for EMAs
        val.Ema1 = Resampled.getStreamAggr("ema1m").val.Val;
        val.Ema2 = Resampled.getStreamAggr("ema10m").val.Val;
        // Get the id of the record from a minute ago.
        var trainRecId = Resampled.getStreamAggr("delay").val.last;;
        // Update the model
        linreg.learn(ftrSpace.ftrVec(Resampled[trainRecId]), val.Value);
    }
});

\end{lstlisting}


\subsection{Graph analysis}
QMiner supports handling of graph data by providing JavaScript API for the integrated SNAP library \cite{snap}. 
This is an example of loading a graph, computing communities and visualizing the results.

The graph represents co-authoring network of Slovenian researchers from biotechnical science in 2013. Nodes of the graph represent researchers, while edges between nodes represent co-authoring of at least on publication. Real networks often have community structure with several regions of internally densely connected nodes. Communities in co-authoring network can indicate groups of strongly connected researchers from a research lab or a similar organization, or simply groups of scientist with a common research interest. Number, sizes and connectivity between communities reveals the cohesiveness of a network.

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.25]{communitiestest.jpg} 
\caption{Communities test figure}
\end{center}
\end{figure}

\begin{lstlisting}[caption=Graph analysis] 
// Import snap module.
snap = require("snap.js");
// Import visualization module.
viz = require("visualization.js");
// Loading a graph file and creating a new undirected graph.
var g = snap.newUGraph("biotechnology_2013.edg");
// Simplifying graph by removing all the nodes with degree 
// smaller or equal to 3.
var g = snap.removeNodes(g, 3);
// computing communities using Clauset-Newman-Moore algorithm
var CmtyCNM = snap.communityDetection(g, "cnm");
// plotting the graph with colors of colors corresponding to communities
viz.drawGraph(g, "graphCNM.html", { "color": CmtyCNM });
\end{lstlisting}

The result shows that...

The complete script is written in JS, while the Clauset-Newman-Moore community detection algorithm \cite{clauset-newman-moore} executes in highly optimized C++ SNAP code.

\section{Conclusions}



\subsubsection*{Acknowledgments}
The authors gratefully acknowledge that the funding for this work was provided by the project X-LIKE (ICT-257790-STREP)\cite{xlike}.


%\subsubsection*{References}

\bibliographystyle{unsrt}
\bibliography{qminer}


\end{document}
